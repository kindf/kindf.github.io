[{"categories":["其他"],"content":"\r主要的数据结构 gobal_State 的成员变量 GCObject **rootgc：存放待 GC 对象的链表，所有对象创建之后都会放入该链表中 GCObject *gray：存放标记为灰色的 GC 对象的链表 struct lua_State：*mainthread：主线程 lu_byte currentwhite：存放当前GC的白色 流程 GC 对象的创建 将对象挂载到扫描过程会遍历的链表（ rootgc ）上 将对象的颜色设置为白色，意指本次GC还未扫描到的对象 初始化阶段（一次完成） 将 mainthread、G 表、registry 表的对象进行标记为灰色 这阶段的标记只是对对象单纯的标记，并没有进行递归的标记，为的是希望这个阶段尽快完成 扫描标记阶段（多次完成） 递归的扫描 gray 链表的对象，将它们及其引用的对象标记为黑色 回收阶段（多次完成） 遍历 rootgc 链表，回收标记为本次回收的白色的对象 结束阶段（多次完成） 回收自带GC元方法的udata对象 几个注意的点 关于 GC 的两种白色及为什么会有两种白色 假如一个对象在 GC 过程的标记阶段之后创建，它应该是白色的，这样在回收阶段，这个对象就会在没有被扫描标记的情况下被认为是没有被引用的对象而删除 关于局部 GC 对象 局部对象就存在于 mainthread 中，查看代码可以知道，在扫描标记阶段的时候，会对 mainthread（lua thread对象） 进行递归的标记，而对 thread 对象进行标记就是递归遍历其局部变量进行标记的 这里只对 GC 过程进行了简单的概括，各种 GC 对象的 GC 操作，barrier 操作等都没涉及，具体可以查看《Lua 设计与实现》第七章的内容 ","date":"2023-12-18","objectID":"/posts/other/lua_gc/:0:0","series":null,"tags":null,"title":"Lua的GC","uri":"/posts/other/lua_gc/#"},{"categories":["其他"],"content":"\r主要的数据结构 gobal_State 的成员变量 GCObject **rootgc：存放待 GC 对象的链表，所有对象创建之后都会放入该链表中 GCObject *gray：存放标记为灰色的 GC 对象的链表 struct lua_State：*mainthread：主线程 lu_byte currentwhite：存放当前GC的白色 流程 GC 对象的创建 将对象挂载到扫描过程会遍历的链表（ rootgc ）上 将对象的颜色设置为白色，意指本次GC还未扫描到的对象 初始化阶段（一次完成） 将 mainthread、G 表、registry 表的对象进行标记为灰色 这阶段的标记只是对对象单纯的标记，并没有进行递归的标记，为的是希望这个阶段尽快完成 扫描标记阶段（多次完成） 递归的扫描 gray 链表的对象，将它们及其引用的对象标记为黑色 回收阶段（多次完成） 遍历 rootgc 链表，回收标记为本次回收的白色的对象 结束阶段（多次完成） 回收自带GC元方法的udata对象 几个注意的点 关于 GC 的两种白色及为什么会有两种白色 假如一个对象在 GC 过程的标记阶段之后创建，它应该是白色的，这样在回收阶段，这个对象就会在没有被扫描标记的情况下被认为是没有被引用的对象而删除 关于局部 GC 对象 局部对象就存在于 mainthread 中，查看代码可以知道，在扫描标记阶段的时候，会对 mainthread（lua thread对象） 进行递归的标记，而对 thread 对象进行标记就是递归遍历其局部变量进行标记的 这里只对 GC 过程进行了简单的概括，各种 GC 对象的 GC 操作，barrier 操作等都没涉及，具体可以查看《Lua 设计与实现》第七章的内容 ","date":"2023-12-18","objectID":"/posts/other/lua_gc/:0:0","series":null,"tags":null,"title":"Lua的GC","uri":"/posts/other/lua_gc/#主要的数据结构"},{"categories":["其他"],"content":"\r主要的数据结构 gobal_State 的成员变量 GCObject **rootgc：存放待 GC 对象的链表，所有对象创建之后都会放入该链表中 GCObject *gray：存放标记为灰色的 GC 对象的链表 struct lua_State：*mainthread：主线程 lu_byte currentwhite：存放当前GC的白色 流程 GC 对象的创建 将对象挂载到扫描过程会遍历的链表（ rootgc ）上 将对象的颜色设置为白色，意指本次GC还未扫描到的对象 初始化阶段（一次完成） 将 mainthread、G 表、registry 表的对象进行标记为灰色 这阶段的标记只是对对象单纯的标记，并没有进行递归的标记，为的是希望这个阶段尽快完成 扫描标记阶段（多次完成） 递归的扫描 gray 链表的对象，将它们及其引用的对象标记为黑色 回收阶段（多次完成） 遍历 rootgc 链表，回收标记为本次回收的白色的对象 结束阶段（多次完成） 回收自带GC元方法的udata对象 几个注意的点 关于 GC 的两种白色及为什么会有两种白色 假如一个对象在 GC 过程的标记阶段之后创建，它应该是白色的，这样在回收阶段，这个对象就会在没有被扫描标记的情况下被认为是没有被引用的对象而删除 关于局部 GC 对象 局部对象就存在于 mainthread 中，查看代码可以知道，在扫描标记阶段的时候，会对 mainthread（lua thread对象） 进行递归的标记，而对 thread 对象进行标记就是递归遍历其局部变量进行标记的 这里只对 GC 过程进行了简单的概括，各种 GC 对象的 GC 操作，barrier 操作等都没涉及，具体可以查看《Lua 设计与实现》第七章的内容 ","date":"2023-12-18","objectID":"/posts/other/lua_gc/:0:0","series":null,"tags":null,"title":"Lua的GC","uri":"/posts/other/lua_gc/#流程"},{"categories":["其他"],"content":"\r主要的数据结构 gobal_State 的成员变量 GCObject **rootgc：存放待 GC 对象的链表，所有对象创建之后都会放入该链表中 GCObject *gray：存放标记为灰色的 GC 对象的链表 struct lua_State：*mainthread：主线程 lu_byte currentwhite：存放当前GC的白色 流程 GC 对象的创建 将对象挂载到扫描过程会遍历的链表（ rootgc ）上 将对象的颜色设置为白色，意指本次GC还未扫描到的对象 初始化阶段（一次完成） 将 mainthread、G 表、registry 表的对象进行标记为灰色 这阶段的标记只是对对象单纯的标记，并没有进行递归的标记，为的是希望这个阶段尽快完成 扫描标记阶段（多次完成） 递归的扫描 gray 链表的对象，将它们及其引用的对象标记为黑色 回收阶段（多次完成） 遍历 rootgc 链表，回收标记为本次回收的白色的对象 结束阶段（多次完成） 回收自带GC元方法的udata对象 几个注意的点 关于 GC 的两种白色及为什么会有两种白色 假如一个对象在 GC 过程的标记阶段之后创建，它应该是白色的，这样在回收阶段，这个对象就会在没有被扫描标记的情况下被认为是没有被引用的对象而删除 关于局部 GC 对象 局部对象就存在于 mainthread 中，查看代码可以知道，在扫描标记阶段的时候，会对 mainthread（lua thread对象） 进行递归的标记，而对 thread 对象进行标记就是递归遍历其局部变量进行标记的 这里只对 GC 过程进行了简单的概括，各种 GC 对象的 GC 操作，barrier 操作等都没涉及，具体可以查看《Lua 设计与实现》第七章的内容 ","date":"2023-12-18","objectID":"/posts/other/lua_gc/:0:0","series":null,"tags":null,"title":"Lua的GC","uri":"/posts/other/lua_gc/#几个注意的点"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#简述"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#服务的结构"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#服务的创建"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#消息队列"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#消息的发送"},{"categories":["skynet相关"],"content":"\r简述 skynet 可以根据动态库（具有一定的规范）动态的创建出服务 skynet启用多线程处理服务处理消息 服务并不会主动执行逻辑，只有当服务接受到消息时才会执行相应的逻辑（包括定时器，skynet 的定时器是以消息的方式通知给服务的） skynet 自带有多个服务如 logger，snlua等，要想比较快的理解 skynet 的服务，可以从比较简单的服务入手（如 logger ） 服务的结构 skynet 服务对应结构体 skynet_context // skynet-src/skynet_server.c struct skynet_context { void * instance; // 服务实例指针 struct skynet_module * mod; // 动态库指针 void * cb_ud; // 用于回调的指针 skynet_cb cb; // 回调函数指针 struct message_queue *queue; // 服务消息队列 FILE * logfile; // for 服务日志 uint64_t cpu_cost; uint64_t cpu_start; char result[32]; // 存放性能指标的查询结果 uint32_t handle; // 服务的id int session_id; // 消息的session id分配器 int ref; // 服务引用计数 int message_count; // 已处理过的消息总数 bool init; // 初始化成功的标识 bool endless; // 死循环标识 bool profile; // cpu 性能指标开启开关 CHECKCALLING_DECL }; 服务的创建 skynet 通过接口 skynet_context_new 动态创建服务 // skynet-src/skynet_server.c 124 struct skynet_context * 125 skynet_context_new(const char * name, const char *param) { 126 struct skynet_module * mod = skynet_module_query(name); 127 128 if (mod == NULL) 129 return NULL; 130 131 void *inst = skynet_module_instance_create(mod); 132 if (inst == NULL) 133 return NULL; 134 struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); 135 CHECKCALLING_INIT(ctx) 136 137 ctx-\u003emod = mod; 138 ctx-\u003einstance = inst; 139 ATOM_INIT(\u0026ctx-\u003eref , 2); 140 ctx-\u003ecb = NULL; 141 ctx-\u003ecb_ud = NULL; 142 ctx-\u003esession_id = 0; 143 ATOM_INIT(\u0026ctx-\u003elogfile, (uintptr_t)NULL); 144 145 ctx-\u003einit = false; 146 ctx-\u003eendless = false; 147 148 ctx-\u003ecpu_cost = 0; 149 ctx-\u003ecpu_start = 0; 150 ctx-\u003emessage_count = 0; 151 ctx-\u003eprofile = G_NODE.profile; 152 // Should set to 0 first to avoid skynet_handle_retireall get an uninitialized handle 153 ctx-\u003ehandle = 0; 154 ctx-\u003ehandle = skynet_handle_register(ctx); 155 struct message_queue * queue = ctx-\u003equeue = skynet_mq_create(ctx-\u003ehandle); 156 // init function maybe use ctx-\u003ehandle, so it must init at last 157 context_inc(); 158 159 CHECKCALLING_BEGIN(ctx) 160 int r = skynet_module_instance_init(mod, inst, ctx, param); 161 CHECKCALLING_END(ctx) 162 if (r == 0) { 163 struct skynet_context * ret = skynet_context_release(ctx); 164 if (ret) { 165 ctx-\u003einit = true; 166 } 167 skynet_globalmq_push(queue); 168 if (ret) { 169 skynet_error(ret, \"LAUNCH %s %s\", name, param ? param : \"\"); 170 } 171 return ret; 172 } else { 173 skynet_error(ctx, \"FAILED launch %s\", name); 174 uint32_t handle = ctx-\u003ehandle; 175 skynet_context_release(ctx); 176 skynet_handle_retire(handle); 177 struct drop_t d = { handle }; 178 skynet_mq_release(queue, drop_message, \u0026d); 179 return NULL; 180 } 181 } 根据 name 通过接口 skynet_module_query 获取对应动态库句柄 mod（ 126 行），mod 中包含四个函数指针（create，init，signal，release） 调用mod 的 create 函数创建实例 inst（ 131 行） 创建 skynet_context 实例 ctx，并进行一系列赋值，把 ctx 注册到 handle_storage （ 134 ~ 154） 创建该服务的消息队列 queue，调用 so 库的 init 函数进行初始化（ 160 行），将 queue 加入到全局队列中 消息队列 // skynet-src/skynet_mq.c 21 struct message_queue { 22 \u003e struct spinlock lock; // 自旋锁 23 \u003e uint32_t handle; // 服务id 24 \u003e int cap; 25 \u003e int head; 26 \u003e int tail; 27 \u003e int release; 28 \u003e int in_global; 29 \u003e int overload; 30 \u003e int overload_threshold; 31 \u003e struct skynet_message *queue; // 消息队列 32 \u003e struct message_queue *next; // 下个队列的指针 33 }; 每个服务实例有都有一个消息队列 message_queue，服务待处理的消息都放在 queue 中 所有的消息队列连成一个链表（ next 指针），全局队列 global_queue 的 head 和 tail 存放这个链表的头指针和尾指针 消息的发送 向服务发送消息，其实就是把消息压入服务的消息队列中 700 int 701 skynet_send(struct skynet_context * context, uint32_t source, uint32_t destination , int type, int session, void * data, size_t sz ) { 702 \u003e if ((sz \u0026 MESSAGE_TYPE_MASK) != sz) { 703 \u003e \u003e skynet_error(context, \"The message to %x is too large\", destination); 704 \u003e \u003e if (type \u0026 PTYPE_TAG_DONTCOPY) { 705 \u003e \u003e \u003e skynet_free(data); 706 \u003e \u003e } 707 \u003e \u003e return -2; 708 \u003e } 709 \u003e _filter_args(context, type, \u0026session, (void **)\u0026data, \u0026sz); 710 711 \u003e if (source == 0) { 712 \u003e \u003e source = context-\u003ehandle; 713 \u003e } 714 715 \u003e if (destination == 0) { 716 \u003e \u003e if (data) { 717 \u003e \u003e \u003e skynet_error(context, \"Destination address can't be 0\"); 718 \u003e \u003e \u003e skynet_free(data); 719 \u003e \u003e \u003e return -1; 720 \u003e \u003e } ","date":"2023-12-16","objectID":"/posts/skynet_cxt/:0:0","series":null,"tags":null,"title":"skynet的服务","uri":"/posts/skynet_cxt/#消息的处理"},{"categories":["skynet相关"],"content":"\r简析 skynet 是一个 actor 模型的框架，actor 就是 skynet 服务，对应代码中的结构体 skynet_context skynet 中存在若干个 skynet_context ，这些对象通过 handle_storage 来进行管理，根据 handle_storage 可以进行增删查操作 ","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:1","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#简析"},{"categories":["skynet相关"],"content":"\r服务管理器 // skynet-src/skynet_handle.c 19 struct handle_storage { 20 struct rwlock lock; 21 22 uint32_t harbor; 23 uint32_t handle_index; // 最后一个服务在数组中的下标 24 int slot_size; // 服务数组的size（最大容量，不足时动态扩展） 25 struct skynet_context ** slot; // 服务的指针数组 26 27 int name_cap; 28 int name_count; 29 struct handle_name *name; // 服务 name 数组，用于根据 name 查询到服务 30 }; skynet 用结构体 handle_storge 来管理其服务 服务的注册 服务的注册接口是 skynet_handle_register ，新创建的服务都是通过该接口加入到管理器中，函数返回服务在 slot 中的下标 // skynet-src/skynet_handle.c 34 uint32_t 35 skynet_handle_register(struct skynet_context *ctx) { 36 struct handle_storage *s = H; 37 38 rwlock_wlock(\u0026s-\u003elock); 39 40 for (;;) { 41 int i; 42 uint32_t handle = s-\u003ehandle_index; 43 for (i=0;i\u003cs-\u003eslot_size;i++,handle++) { 44 if (handle \u003e HANDLE_MASK) { 45 // 0 is reserved 46 handle = 1; 47 } 48 int hash = handle \u0026 (s-\u003eslot_size-1); 49 if (s-\u003eslot[hash] == NULL) { 50 s-\u003eslot[hash] = ctx; 51 s-\u003ehandle_index = handle + 1; 52 53 rwlock_wunlock(\u0026s-\u003elock); 54 55 handle |= s-\u003eharbor; 56 return handle; 57 } 58 } 59 assert((s-\u003eslot_size*2 - 1) \u003c= HANDLE_MASK); 60 struct skynet_context ** new_slot = skynet_malloc(s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 61 memset(new_slot, 0, s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 62 for (i=0;i\u003cs-\u003eslot_size;i++) { 63 if (s-\u003eslot[i]) { 64 int hash = skynet_context_handle(s-\u003eslot[i]) \u0026 (s-\u003eslot_size * 2 - 1); 65 assert(new_slot[hash] == NULL); 66 new_slot[hash] = s-\u003eslot[i]; 67 } 68 } 69 skynet_free(s-\u003eslot); 70 s-\u003eslot = new_slot; 71 s-\u003eslot_size *= 2; 72 } 73 } 如果容量足够，直接加入到 slot 中（ 43 ~ 56），并返回其在 slot 中的下标 容量不足时动态扩容为原来容量的两倍，将旧数据迁移到新数组中（ 60 ~ 71 ） 服务的查询// skynet-src/skynet_handle.c 138 struct skynet_context * 139 skynet_handle_grab(uint32_t handle) { 140 struct handle_storage *s = H; 141 struct skynet_context * result = NULL; 142 143 rwlock_rlock(\u0026s-\u003elock); 144 145 uint32_t hash = handle \u0026 (s-\u003eslot_size-1); 146 struct skynet_context * ctx = s-\u003eslot[hash]; 147 if (ctx \u0026\u0026 skynet_context_handle(ctx) == handle) { 148 result = ctx; 149 skynet_context_grab(result); 150 } 151 152 rwlock_runlock(\u0026s-\u003elock); 153 154 return result; 155 } skynet 提供根据 handle 查询到 skynet_context 的接口 skynet_handle_grab skynet 提供为服务命名的接口（ skynet_handle_namehandle ），该接口将 name 和 handle 建立对应关系，这样就可以凭借 name 查询到对应的服务（ skynet_handle_findname ），代码都在文件 skynet-src/skynet_handle.h 中，这里不多赘述 服务的调度 skynet 启用多线程来分发消息，线程最终都会调用到函数 skynet_context_message_dispatch // skynet-src/skynet_server.c 297 struct message_queue *- 298 skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { 299 \u003e if (q == NULL) { 300 \u003e \u003e q = skynet_globalmq_pop(); 301 \u003e \u003e if (q==NULL) 302 \u003e \u003e \u003e return NULL; 303 \u003e } 304 305 \u003e uint32_t handle = skynet_mq_handle(q); 306 307 \u003e struct skynet_context * ctx = skynet_handle_grab(handle); 308 \u003e if (ctx == NULL) { 309 \u003e \u003e struct drop_t d = { handle }; 310 \u003e \u003e skynet_mq_release(q, drop_message, \u0026d); 311 \u003e \u003e return skynet_globalmq_pop(); 312 \u003e } 313 314 \u003e int i,n=1; 315 \u003e struct skynet_message msg; 316 317 \u003e for (i=0;i\u003cn;i++) { 318 \u003e \u003e if (skynet_mq_pop(q,\u0026msg)) { 319 \u003e \u003e \u003e skynet_context_release(ctx); 320 \u003e \u003e \u003e return skynet_globalmq_pop(); 321 \u003e \u003e } else if (i==0 \u0026\u0026 weight \u003e= 0) { 322 \u003e \u003e \u003e n = skynet_mq_length(q); 323 \u003e \u003e \u003e n \u003e\u003e= weight; 324 \u003e \u003e } 325 \u003e \u003e int overload = skynet_mq_overload(q); 326 \u003e \u003e if (overload) { 327 \u003e \u003e \u003e skynet_error(ctx, \"May overload, message queue length = %d\", overload); 328 \u003e \u003e } 329 330 \u003e \u003e skynet_monitor_trigger(sm, msg.source , handle); 331 332 \u003e \u003e if (ctx-\u003ecb == NULL) { 333 \u003e \u003e \u003e skynet_free(msg.data); 334 \u003e \u003e } else { 335 \u003e \u003e \u003e dispatch_message(ctx, \u0026msg); 336 \u003e \u003e } 337 338 \u003e \u003e skynet_monitor_trigger(sm, 0,0); 339 \u003e } 340 341 \u003e assert(q == ctx-\u003equeue); 342 \u003e struct message_queue *nq = skynet_globalmq_pop(); 343 \u003e if (nq) { 344 \u003e \u003e // If global mq is not empty , push q back, and return next queue (nq) 345 \u003e \u003e // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) 346 \u003e \u003e skynet_globalmq_push(q); 347 \u003e \u003e q = n","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:2","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#服务管理器"},{"categories":["skynet相关"],"content":"\r服务管理器 // skynet-src/skynet_handle.c 19 struct handle_storage { 20 struct rwlock lock; 21 22 uint32_t harbor; 23 uint32_t handle_index; // 最后一个服务在数组中的下标 24 int slot_size; // 服务数组的size（最大容量，不足时动态扩展） 25 struct skynet_context ** slot; // 服务的指针数组 26 27 int name_cap; 28 int name_count; 29 struct handle_name *name; // 服务 name 数组，用于根据 name 查询到服务 30 }; skynet 用结构体 handle_storge 来管理其服务 服务的注册 服务的注册接口是 skynet_handle_register ，新创建的服务都是通过该接口加入到管理器中，函数返回服务在 slot 中的下标 // skynet-src/skynet_handle.c 34 uint32_t 35 skynet_handle_register(struct skynet_context *ctx) { 36 struct handle_storage *s = H; 37 38 rwlock_wlock(\u0026s-\u003elock); 39 40 for (;;) { 41 int i; 42 uint32_t handle = s-\u003ehandle_index; 43 for (i=0;islot_size;i++,handle++) { 44 if (handle \u003e HANDLE_MASK) { 45 // 0 is reserved 46 handle = 1; 47 } 48 int hash = handle \u0026 (s-\u003eslot_size-1); 49 if (s-\u003eslot[hash] == NULL) { 50 s-\u003eslot[hash] = ctx; 51 s-\u003ehandle_index = handle + 1; 52 53 rwlock_wunlock(\u0026s-\u003elock); 54 55 handle |= s-\u003eharbor; 56 return handle; 57 } 58 } 59 assert((s-\u003eslot_size*2 - 1) \u003c= HANDLE_MASK); 60 struct skynet_context ** new_slot = skynet_malloc(s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 61 memset(new_slot, 0, s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 62 for (i=0;islot_size;i++) { 63 if (s-\u003eslot[i]) { 64 int hash = skynet_context_handle(s-\u003eslot[i]) \u0026 (s-\u003eslot_size * 2 - 1); 65 assert(new_slot[hash] == NULL); 66 new_slot[hash] = s-\u003eslot[i]; 67 } 68 } 69 skynet_free(s-\u003eslot); 70 s-\u003eslot = new_slot; 71 s-\u003eslot_size *= 2; 72 } 73 } 如果容量足够，直接加入到 slot 中（ 43 ~ 56），并返回其在 slot 中的下标 容量不足时动态扩容为原来容量的两倍，将旧数据迁移到新数组中（ 60 ~ 71 ） 服务的查询// skynet-src/skynet_handle.c 138 struct skynet_context * 139 skynet_handle_grab(uint32_t handle) { 140 struct handle_storage *s = H; 141 struct skynet_context * result = NULL; 142 143 rwlock_rlock(\u0026s-\u003elock); 144 145 uint32_t hash = handle \u0026 (s-\u003eslot_size-1); 146 struct skynet_context * ctx = s-\u003eslot[hash]; 147 if (ctx \u0026\u0026 skynet_context_handle(ctx) == handle) { 148 result = ctx; 149 skynet_context_grab(result); 150 } 151 152 rwlock_runlock(\u0026s-\u003elock); 153 154 return result; 155 } skynet 提供根据 handle 查询到 skynet_context 的接口 skynet_handle_grab skynet 提供为服务命名的接口（ skynet_handle_namehandle ），该接口将 name 和 handle 建立对应关系，这样就可以凭借 name 查询到对应的服务（ skynet_handle_findname ），代码都在文件 skynet-src/skynet_handle.h 中，这里不多赘述 服务的调度 skynet 启用多线程来分发消息，线程最终都会调用到函数 skynet_context_message_dispatch // skynet-src/skynet_server.c 297 struct message_queue *- 298 skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { 299 \u003e if (q == NULL) { 300 \u003e \u003e q = skynet_globalmq_pop(); 301 \u003e \u003e if (q==NULL) 302 \u003e \u003e \u003e return NULL; 303 \u003e } 304 305 \u003e uint32_t handle = skynet_mq_handle(q); 306 307 \u003e struct skynet_context * ctx = skynet_handle_grab(handle); 308 \u003e if (ctx == NULL) { 309 \u003e \u003e struct drop_t d = { handle }; 310 \u003e \u003e skynet_mq_release(q, drop_message, \u0026d); 311 \u003e \u003e return skynet_globalmq_pop(); 312 \u003e } 313 314 \u003e int i,n=1; 315 \u003e struct skynet_message msg; 316 317 \u003e for (i=0;i \u003e if (skynet_mq_pop(q,\u0026msg)) { 319 \u003e \u003e \u003e skynet_context_release(ctx); 320 \u003e \u003e \u003e return skynet_globalmq_pop(); 321 \u003e \u003e } else if (i==0 \u0026\u0026 weight \u003e= 0) { 322 \u003e \u003e \u003e n = skynet_mq_length(q); 323 \u003e \u003e \u003e n \u003e\u003e= weight; 324 \u003e \u003e } 325 \u003e \u003e int overload = skynet_mq_overload(q); 326 \u003e \u003e if (overload) { 327 \u003e \u003e \u003e skynet_error(ctx, \"May overload, message queue length = %d\", overload); 328 \u003e \u003e } 329 330 \u003e \u003e skynet_monitor_trigger(sm, msg.source , handle); 331 332 \u003e \u003e if (ctx-\u003ecb == NULL) { 333 \u003e \u003e \u003e skynet_free(msg.data); 334 \u003e \u003e } else { 335 \u003e \u003e \u003e dispatch_message(ctx, \u0026msg); 336 \u003e \u003e } 337 338 \u003e \u003e skynet_monitor_trigger(sm, 0,0); 339 \u003e } 340 341 \u003e assert(q == ctx-\u003equeue); 342 \u003e struct message_queue *nq = skynet_globalmq_pop(); 343 \u003e if (nq) { 344 \u003e \u003e // If global mq is not empty , push q back, and return next queue (nq) 345 \u003e \u003e // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) 346 \u003e \u003e skynet_globalmq_push(q); 347 \u003e \u003e q = n","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:2","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#服务的注册"},{"categories":["skynet相关"],"content":"\r服务管理器 // skynet-src/skynet_handle.c 19 struct handle_storage { 20 struct rwlock lock; 21 22 uint32_t harbor; 23 uint32_t handle_index; // 最后一个服务在数组中的下标 24 int slot_size; // 服务数组的size（最大容量，不足时动态扩展） 25 struct skynet_context ** slot; // 服务的指针数组 26 27 int name_cap; 28 int name_count; 29 struct handle_name *name; // 服务 name 数组，用于根据 name 查询到服务 30 }; skynet 用结构体 handle_storge 来管理其服务 服务的注册 服务的注册接口是 skynet_handle_register ，新创建的服务都是通过该接口加入到管理器中，函数返回服务在 slot 中的下标 // skynet-src/skynet_handle.c 34 uint32_t 35 skynet_handle_register(struct skynet_context *ctx) { 36 struct handle_storage *s = H; 37 38 rwlock_wlock(\u0026s-\u003elock); 39 40 for (;;) { 41 int i; 42 uint32_t handle = s-\u003ehandle_index; 43 for (i=0;islot_size;i++,handle++) { 44 if (handle \u003e HANDLE_MASK) { 45 // 0 is reserved 46 handle = 1; 47 } 48 int hash = handle \u0026 (s-\u003eslot_size-1); 49 if (s-\u003eslot[hash] == NULL) { 50 s-\u003eslot[hash] = ctx; 51 s-\u003ehandle_index = handle + 1; 52 53 rwlock_wunlock(\u0026s-\u003elock); 54 55 handle |= s-\u003eharbor; 56 return handle; 57 } 58 } 59 assert((s-\u003eslot_size*2 - 1) \u003c= HANDLE_MASK); 60 struct skynet_context ** new_slot = skynet_malloc(s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 61 memset(new_slot, 0, s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 62 for (i=0;islot_size;i++) { 63 if (s-\u003eslot[i]) { 64 int hash = skynet_context_handle(s-\u003eslot[i]) \u0026 (s-\u003eslot_size * 2 - 1); 65 assert(new_slot[hash] == NULL); 66 new_slot[hash] = s-\u003eslot[i]; 67 } 68 } 69 skynet_free(s-\u003eslot); 70 s-\u003eslot = new_slot; 71 s-\u003eslot_size *= 2; 72 } 73 } 如果容量足够，直接加入到 slot 中（ 43 ~ 56），并返回其在 slot 中的下标 容量不足时动态扩容为原来容量的两倍，将旧数据迁移到新数组中（ 60 ~ 71 ） 服务的查询// skynet-src/skynet_handle.c 138 struct skynet_context * 139 skynet_handle_grab(uint32_t handle) { 140 struct handle_storage *s = H; 141 struct skynet_context * result = NULL; 142 143 rwlock_rlock(\u0026s-\u003elock); 144 145 uint32_t hash = handle \u0026 (s-\u003eslot_size-1); 146 struct skynet_context * ctx = s-\u003eslot[hash]; 147 if (ctx \u0026\u0026 skynet_context_handle(ctx) == handle) { 148 result = ctx; 149 skynet_context_grab(result); 150 } 151 152 rwlock_runlock(\u0026s-\u003elock); 153 154 return result; 155 } skynet 提供根据 handle 查询到 skynet_context 的接口 skynet_handle_grab skynet 提供为服务命名的接口（ skynet_handle_namehandle ），该接口将 name 和 handle 建立对应关系，这样就可以凭借 name 查询到对应的服务（ skynet_handle_findname ），代码都在文件 skynet-src/skynet_handle.h 中，这里不多赘述 服务的调度 skynet 启用多线程来分发消息，线程最终都会调用到函数 skynet_context_message_dispatch // skynet-src/skynet_server.c 297 struct message_queue *- 298 skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { 299 \u003e if (q == NULL) { 300 \u003e \u003e q = skynet_globalmq_pop(); 301 \u003e \u003e if (q==NULL) 302 \u003e \u003e \u003e return NULL; 303 \u003e } 304 305 \u003e uint32_t handle = skynet_mq_handle(q); 306 307 \u003e struct skynet_context * ctx = skynet_handle_grab(handle); 308 \u003e if (ctx == NULL) { 309 \u003e \u003e struct drop_t d = { handle }; 310 \u003e \u003e skynet_mq_release(q, drop_message, \u0026d); 311 \u003e \u003e return skynet_globalmq_pop(); 312 \u003e } 313 314 \u003e int i,n=1; 315 \u003e struct skynet_message msg; 316 317 \u003e for (i=0;i \u003e if (skynet_mq_pop(q,\u0026msg)) { 319 \u003e \u003e \u003e skynet_context_release(ctx); 320 \u003e \u003e \u003e return skynet_globalmq_pop(); 321 \u003e \u003e } else if (i==0 \u0026\u0026 weight \u003e= 0) { 322 \u003e \u003e \u003e n = skynet_mq_length(q); 323 \u003e \u003e \u003e n \u003e\u003e= weight; 324 \u003e \u003e } 325 \u003e \u003e int overload = skynet_mq_overload(q); 326 \u003e \u003e if (overload) { 327 \u003e \u003e \u003e skynet_error(ctx, \"May overload, message queue length = %d\", overload); 328 \u003e \u003e } 329 330 \u003e \u003e skynet_monitor_trigger(sm, msg.source , handle); 331 332 \u003e \u003e if (ctx-\u003ecb == NULL) { 333 \u003e \u003e \u003e skynet_free(msg.data); 334 \u003e \u003e } else { 335 \u003e \u003e \u003e dispatch_message(ctx, \u0026msg); 336 \u003e \u003e } 337 338 \u003e \u003e skynet_monitor_trigger(sm, 0,0); 339 \u003e } 340 341 \u003e assert(q == ctx-\u003equeue); 342 \u003e struct message_queue *nq = skynet_globalmq_pop(); 343 \u003e if (nq) { 344 \u003e \u003e // If global mq is not empty , push q back, and return next queue (nq) 345 \u003e \u003e // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) 346 \u003e \u003e skynet_globalmq_push(q); 347 \u003e \u003e q = n","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:2","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#服务的查询"},{"categories":["skynet相关"],"content":"\r服务管理器 // skynet-src/skynet_handle.c 19 struct handle_storage { 20 struct rwlock lock; 21 22 uint32_t harbor; 23 uint32_t handle_index; // 最后一个服务在数组中的下标 24 int slot_size; // 服务数组的size（最大容量，不足时动态扩展） 25 struct skynet_context ** slot; // 服务的指针数组 26 27 int name_cap; 28 int name_count; 29 struct handle_name *name; // 服务 name 数组，用于根据 name 查询到服务 30 }; skynet 用结构体 handle_storge 来管理其服务 服务的注册 服务的注册接口是 skynet_handle_register ，新创建的服务都是通过该接口加入到管理器中，函数返回服务在 slot 中的下标 // skynet-src/skynet_handle.c 34 uint32_t 35 skynet_handle_register(struct skynet_context *ctx) { 36 struct handle_storage *s = H; 37 38 rwlock_wlock(\u0026s-\u003elock); 39 40 for (;;) { 41 int i; 42 uint32_t handle = s-\u003ehandle_index; 43 for (i=0;islot_size;i++,handle++) { 44 if (handle \u003e HANDLE_MASK) { 45 // 0 is reserved 46 handle = 1; 47 } 48 int hash = handle \u0026 (s-\u003eslot_size-1); 49 if (s-\u003eslot[hash] == NULL) { 50 s-\u003eslot[hash] = ctx; 51 s-\u003ehandle_index = handle + 1; 52 53 rwlock_wunlock(\u0026s-\u003elock); 54 55 handle |= s-\u003eharbor; 56 return handle; 57 } 58 } 59 assert((s-\u003eslot_size*2 - 1) \u003c= HANDLE_MASK); 60 struct skynet_context ** new_slot = skynet_malloc(s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 61 memset(new_slot, 0, s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 62 for (i=0;islot_size;i++) { 63 if (s-\u003eslot[i]) { 64 int hash = skynet_context_handle(s-\u003eslot[i]) \u0026 (s-\u003eslot_size * 2 - 1); 65 assert(new_slot[hash] == NULL); 66 new_slot[hash] = s-\u003eslot[i]; 67 } 68 } 69 skynet_free(s-\u003eslot); 70 s-\u003eslot = new_slot; 71 s-\u003eslot_size *= 2; 72 } 73 } 如果容量足够，直接加入到 slot 中（ 43 ~ 56），并返回其在 slot 中的下标 容量不足时动态扩容为原来容量的两倍，将旧数据迁移到新数组中（ 60 ~ 71 ） 服务的查询// skynet-src/skynet_handle.c 138 struct skynet_context * 139 skynet_handle_grab(uint32_t handle) { 140 struct handle_storage *s = H; 141 struct skynet_context * result = NULL; 142 143 rwlock_rlock(\u0026s-\u003elock); 144 145 uint32_t hash = handle \u0026 (s-\u003eslot_size-1); 146 struct skynet_context * ctx = s-\u003eslot[hash]; 147 if (ctx \u0026\u0026 skynet_context_handle(ctx) == handle) { 148 result = ctx; 149 skynet_context_grab(result); 150 } 151 152 rwlock_runlock(\u0026s-\u003elock); 153 154 return result; 155 } skynet 提供根据 handle 查询到 skynet_context 的接口 skynet_handle_grab skynet 提供为服务命名的接口（ skynet_handle_namehandle ），该接口将 name 和 handle 建立对应关系，这样就可以凭借 name 查询到对应的服务（ skynet_handle_findname ），代码都在文件 skynet-src/skynet_handle.h 中，这里不多赘述 服务的调度 skynet 启用多线程来分发消息，线程最终都会调用到函数 skynet_context_message_dispatch // skynet-src/skynet_server.c 297 struct message_queue *- 298 skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { 299 \u003e if (q == NULL) { 300 \u003e \u003e q = skynet_globalmq_pop(); 301 \u003e \u003e if (q==NULL) 302 \u003e \u003e \u003e return NULL; 303 \u003e } 304 305 \u003e uint32_t handle = skynet_mq_handle(q); 306 307 \u003e struct skynet_context * ctx = skynet_handle_grab(handle); 308 \u003e if (ctx == NULL) { 309 \u003e \u003e struct drop_t d = { handle }; 310 \u003e \u003e skynet_mq_release(q, drop_message, \u0026d); 311 \u003e \u003e return skynet_globalmq_pop(); 312 \u003e } 313 314 \u003e int i,n=1; 315 \u003e struct skynet_message msg; 316 317 \u003e for (i=0;i \u003e if (skynet_mq_pop(q,\u0026msg)) { 319 \u003e \u003e \u003e skynet_context_release(ctx); 320 \u003e \u003e \u003e return skynet_globalmq_pop(); 321 \u003e \u003e } else if (i==0 \u0026\u0026 weight \u003e= 0) { 322 \u003e \u003e \u003e n = skynet_mq_length(q); 323 \u003e \u003e \u003e n \u003e\u003e= weight; 324 \u003e \u003e } 325 \u003e \u003e int overload = skynet_mq_overload(q); 326 \u003e \u003e if (overload) { 327 \u003e \u003e \u003e skynet_error(ctx, \"May overload, message queue length = %d\", overload); 328 \u003e \u003e } 329 330 \u003e \u003e skynet_monitor_trigger(sm, msg.source , handle); 331 332 \u003e \u003e if (ctx-\u003ecb == NULL) { 333 \u003e \u003e \u003e skynet_free(msg.data); 334 \u003e \u003e } else { 335 \u003e \u003e \u003e dispatch_message(ctx, \u0026msg); 336 \u003e \u003e } 337 338 \u003e \u003e skynet_monitor_trigger(sm, 0,0); 339 \u003e } 340 341 \u003e assert(q == ctx-\u003equeue); 342 \u003e struct message_queue *nq = skynet_globalmq_pop(); 343 \u003e if (nq) { 344 \u003e \u003e // If global mq is not empty , push q back, and return next queue (nq) 345 \u003e \u003e // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) 346 \u003e \u003e skynet_globalmq_push(q); 347 \u003e \u003e q = n","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:2","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#服务的调度"},{"categories":["skynet相关"],"content":"\r服务管理器 // skynet-src/skynet_handle.c 19 struct handle_storage { 20 struct rwlock lock; 21 22 uint32_t harbor; 23 uint32_t handle_index; // 最后一个服务在数组中的下标 24 int slot_size; // 服务数组的size（最大容量，不足时动态扩展） 25 struct skynet_context ** slot; // 服务的指针数组 26 27 int name_cap; 28 int name_count; 29 struct handle_name *name; // 服务 name 数组，用于根据 name 查询到服务 30 }; skynet 用结构体 handle_storge 来管理其服务 服务的注册 服务的注册接口是 skynet_handle_register ，新创建的服务都是通过该接口加入到管理器中，函数返回服务在 slot 中的下标 // skynet-src/skynet_handle.c 34 uint32_t 35 skynet_handle_register(struct skynet_context *ctx) { 36 struct handle_storage *s = H; 37 38 rwlock_wlock(\u0026s-\u003elock); 39 40 for (;;) { 41 int i; 42 uint32_t handle = s-\u003ehandle_index; 43 for (i=0;islot_size;i++,handle++) { 44 if (handle \u003e HANDLE_MASK) { 45 // 0 is reserved 46 handle = 1; 47 } 48 int hash = handle \u0026 (s-\u003eslot_size-1); 49 if (s-\u003eslot[hash] == NULL) { 50 s-\u003eslot[hash] = ctx; 51 s-\u003ehandle_index = handle + 1; 52 53 rwlock_wunlock(\u0026s-\u003elock); 54 55 handle |= s-\u003eharbor; 56 return handle; 57 } 58 } 59 assert((s-\u003eslot_size*2 - 1) \u003c= HANDLE_MASK); 60 struct skynet_context ** new_slot = skynet_malloc(s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 61 memset(new_slot, 0, s-\u003eslot_size * 2 * sizeof(struct skynet_context *)); 62 for (i=0;islot_size;i++) { 63 if (s-\u003eslot[i]) { 64 int hash = skynet_context_handle(s-\u003eslot[i]) \u0026 (s-\u003eslot_size * 2 - 1); 65 assert(new_slot[hash] == NULL); 66 new_slot[hash] = s-\u003eslot[i]; 67 } 68 } 69 skynet_free(s-\u003eslot); 70 s-\u003eslot = new_slot; 71 s-\u003eslot_size *= 2; 72 } 73 } 如果容量足够，直接加入到 slot 中（ 43 ~ 56），并返回其在 slot 中的下标 容量不足时动态扩容为原来容量的两倍，将旧数据迁移到新数组中（ 60 ~ 71 ） 服务的查询// skynet-src/skynet_handle.c 138 struct skynet_context * 139 skynet_handle_grab(uint32_t handle) { 140 struct handle_storage *s = H; 141 struct skynet_context * result = NULL; 142 143 rwlock_rlock(\u0026s-\u003elock); 144 145 uint32_t hash = handle \u0026 (s-\u003eslot_size-1); 146 struct skynet_context * ctx = s-\u003eslot[hash]; 147 if (ctx \u0026\u0026 skynet_context_handle(ctx) == handle) { 148 result = ctx; 149 skynet_context_grab(result); 150 } 151 152 rwlock_runlock(\u0026s-\u003elock); 153 154 return result; 155 } skynet 提供根据 handle 查询到 skynet_context 的接口 skynet_handle_grab skynet 提供为服务命名的接口（ skynet_handle_namehandle ），该接口将 name 和 handle 建立对应关系，这样就可以凭借 name 查询到对应的服务（ skynet_handle_findname ），代码都在文件 skynet-src/skynet_handle.h 中，这里不多赘述 服务的调度 skynet 启用多线程来分发消息，线程最终都会调用到函数 skynet_context_message_dispatch // skynet-src/skynet_server.c 297 struct message_queue *- 298 skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { 299 \u003e if (q == NULL) { 300 \u003e \u003e q = skynet_globalmq_pop(); 301 \u003e \u003e if (q==NULL) 302 \u003e \u003e \u003e return NULL; 303 \u003e } 304 305 \u003e uint32_t handle = skynet_mq_handle(q); 306 307 \u003e struct skynet_context * ctx = skynet_handle_grab(handle); 308 \u003e if (ctx == NULL) { 309 \u003e \u003e struct drop_t d = { handle }; 310 \u003e \u003e skynet_mq_release(q, drop_message, \u0026d); 311 \u003e \u003e return skynet_globalmq_pop(); 312 \u003e } 313 314 \u003e int i,n=1; 315 \u003e struct skynet_message msg; 316 317 \u003e for (i=0;i \u003e if (skynet_mq_pop(q,\u0026msg)) { 319 \u003e \u003e \u003e skynet_context_release(ctx); 320 \u003e \u003e \u003e return skynet_globalmq_pop(); 321 \u003e \u003e } else if (i==0 \u0026\u0026 weight \u003e= 0) { 322 \u003e \u003e \u003e n = skynet_mq_length(q); 323 \u003e \u003e \u003e n \u003e\u003e= weight; 324 \u003e \u003e } 325 \u003e \u003e int overload = skynet_mq_overload(q); 326 \u003e \u003e if (overload) { 327 \u003e \u003e \u003e skynet_error(ctx, \"May overload, message queue length = %d\", overload); 328 \u003e \u003e } 329 330 \u003e \u003e skynet_monitor_trigger(sm, msg.source , handle); 331 332 \u003e \u003e if (ctx-\u003ecb == NULL) { 333 \u003e \u003e \u003e skynet_free(msg.data); 334 \u003e \u003e } else { 335 \u003e \u003e \u003e dispatch_message(ctx, \u0026msg); 336 \u003e \u003e } 337 338 \u003e \u003e skynet_monitor_trigger(sm, 0,0); 339 \u003e } 340 341 \u003e assert(q == ctx-\u003equeue); 342 \u003e struct message_queue *nq = skynet_globalmq_pop(); 343 \u003e if (nq) { 344 \u003e \u003e // If global mq is not empty , push q back, and return next queue (nq) 345 \u003e \u003e // Else (global mq is empty or block, don't push q back, and return q again (for next dispatch) 346 \u003e \u003e skynet_globalmq_push(q); 347 \u003e \u003e q = n","date":"2023-12-15","objectID":"/posts/skynet/skynet_hs/:0:2","series":null,"tags":null,"title":"skynet的服务管理","uri":"/posts/skynet/skynet_hs/#服务的关闭"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i\u003cdiff;i++) { 257 \u003e \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#简析"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#主要结构"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#tick函数"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#主要流程"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#定时器的插入"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#定时器的执行"},{"categories":["skynet相关"],"content":"\r简析 skyent 用 5 个链表数组来存储定时事件，分别是 near[256] 和 t[4]，其中 near 数组用来存放即将到期的定时事件，t[0] ~ t[3] 数组分别存放不同时间段的定时事件 插入时，定时器根据过期时间 expire 和当前时间 now 的相对时间，将事件放到对应的链表当中 tick的时候，定时器直接取 near 中的到期事件触发 每过一定时间，定时器将 t[0] ~ t[3] 中的事件重新分配到合适的位置 主要结构 39 \u003e struct timer { 40 \u003e struct link_list near[TIME_NEAR]; //到期时间较近定时器事件链表 41 \u003e struct link_list t[4][TIME_LEVEL]; //定时器事件链表 42 \u003e struct spinlock lock; //自旋锁 43 \u003e uint32_t time; //启动后tick的时间 44 \u003e uint32_t starttime; //启动时的系统时间 45 \u003e uint64_t current; //skynet自己计算出的实际时间 46 \u003e uint64_t current_point; //系统启动后的绝对时间 47 }; skynet定时器的基本思想就是把到期时间较近的事件放到near数组中，其余的放到t数值中，每次tick后就从near数组中找到到期的事件触发 tick函数 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); 174 175 \u003e timer_execute(T); 176 177 \u003e SPIN_UNLOCK(T); 178 } 245 void 246 skynet_updatetime(void) { 247 \u003e uint64_t cp = gettime(); 248 \u003e if(cp \u003c TI-\u003ecurrent_point) { 249 \u003e \u003e skynet_error(NULL, \"time diff error: change from %lld to %lld\", cp, TI-\u003ecurrent_point); 250 \u003e \u003e TI-\u003ecurrent_point = cp; 251 \u003e } else if (cp != TI-\u003ecurrent_point) { 252 \u003e \u003e uint32_t diff = (uint32_t)(cp - TI-\u003ecurrent_point); 253 \u003e \u003e TI-\u003ecurrent_point = cp; 254 \u003e \u003e TI-\u003ecurrent += diff; 255 \u003e \u003e int i; 256 \u003e \u003e for (i=0;i \u003e \u003e timer_update(TI); 258 \u003e \u003e } 259 \u003e } 260 } skynet的timer线程每2500微秒（即2.5毫秒）执行一次skynet_updatetime 主要流程 165 static void- 166 timer_update(struct timer *T) { 167 \u003e SPIN_LOCK(T); 168 169 \u003e // try to dispatch timeout 0 (rare condition) 170 \u003e timer_execute(T); // 触发定时器 171 172 \u003e // shift time first, and then dispatch timer message 173 \u003e timer_shift(T); // 过期时间再分配 174 175 \u003e timer_execute(T); // 触发定时器 176 177 \u003e SPIN_UNLOCK(T); 178 } 这里执行了两次timer_execute，按理来说，第一次timer_execute并不是必须的，因为注册过期时间为现在的事件是直接分发事件而不进入到定时器中。对于为啥执行两次的解释，作者希望timer 不需要关注 skynet 的用法实现，即不管skynet有没有处理time==0的情况，timer都不会因此出现bug 定时器的插入 67 static void 68 add_node(struct timer *T,struct timer_node *node) { 69 \u003e uint32_t time=node-\u003eexpire; // 过期时间 70 \u003e uint32_t current_time=T-\u003etime; // 当前时间 71 \u003e 72 \u003e if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 将较近的放到near数组中 73 \u003e \u003e link(\u0026T-\u003enear[time\u0026TIME_NEAR_MASK],node); 74 \u003e } else { 75 \u003e \u003e int i; 76 \u003e \u003e uint32_t mask=TIME_NEAR \u003c\u003c TIME_LEVEL_SHIFT; 77 \u003e \u003e for (i=0;i\u003c3;i++) { 78 \u003e \u003e \u003e if ((time|(mask-1))==(current_time|(mask-1))) { 79 \u003e \u003e \u003e \u003e break; 80 \u003e \u003e \u003e } 81 \u003e \u003e \u003e mask \u003c\u003c= TIME_LEVEL_SHIFT; 82 \u003e \u003e } 83 84 \u003e \u003e link(\u0026T-\u003et[i][((time\u003e\u003e(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026 TIME_LEVEL_MASK)],node);\u003e // 根据过期时间的长短放到 t 中 85 \u003e } 86 } 分析： 将和 current_time 高 24 位相同的 time 放到 near[x] 中，x 为 time 的第 0 ~ 7 位表示的十进制值（如 time 的第 0 ~ 7 位为 00000010时，放到 near[2] 中） 将和 current_time 高 18 位相同的 time 放到 t[0][x]中，x 为 time 的第 8 ~ 14 位表示的十进制值（如 time 的第 8 ~ 14 位为 000010时，放到 t[0][2] 中） 将和 current_time 高 12 位相同的 time 放到 t[1][x]中，x 为 time 的第 15 ~ 21 位表示的十进制值（如 time 的第 15 ~ 21 位为 000010时，放到 t[1][2] 中） 将和 current_time 高 6 位相同的 time 放到 t[2][x]中，x 为 time 的第 22 ~ 27 位表示的十进制值（如 time 的第 22 ~ 27 位为 000010时，放到 t[2][2] 中） 将其余的 time 放到 t[3][x] 中，x 为 time 的第 28 ~ 32 位表示的十进制值（如 time 的第 28 ~ 32 位为 000010时，放到 t[3][2] 中） 定时器的执行 152 static inline void 153 timer_execute(struct timer *T) { 154 \u003e int idx = T-\u003etime \u0026 TIME_NEAR_MASK; 155 \u003e 156 \u003e while (T-\u003enear[idx].head.next) { 157 \u003e \u003e struct timer_node *current = link_clear(\u0026T-\u003enear[idx]); 158 \u003e \u003e SPIN_UNLOCK(T); 159 \u003e \u003e // dispatch_list don't need lock T 160 \u003e \u003e dispatch_list(current); 161 \u003e \u003e SPIN_LOCK(T); 162 \u003e } 163 } 因为最近的事件都在near上，只需要根据idx就能找到到期的事件 过期事件的再分配 101 static void 102 move_list(struct timer *T, int level, int idx) { 103 \u003e struct timer_node *current = link_clear(\u0026T-\u003et[level][idx]); 104 \u003e while (current) { 105 \u003e \u003e struct timer_node *temp=current-\u003enext; 106 \u003e \u003e add_node(T,current); 107 \u003e \u003e current=temp; 108 \u003e } 109 } 111 static void 112 timer_shift(struct timer *T) { 113 \u003e int mask = TIME_NEAR; 114 \u003e uint32_t ct = ++T-\u003etime; 115 \u003e if (ct == 0) { 116 \u003e \u003e move_list(T, ","date":"2023-11-14","objectID":"/posts/skynet/skynet_timer/:0:0","series":null,"tags":null,"title":"skynet的定时器","uri":"/posts/skynet/skynet_timer/#过期事件的再分配"},{"categories":["skynet相关"],"content":"\r简析 skynet 创建专门的 socket 线程用于处理 socket 相关的逻辑。skynet 将 socket 相关的操作提炼出 lua 接口供用于在 lua 层操作 socket lua 层 与 socket 层并不在同一个线程内，lua 层向 socket 线程发送消息是通过管道，而 socket 层向 lua 层发送消息是通过 skynet 的消息系统 ","date":"2023-11-01","objectID":"/posts/skynet/skynet_net/:0:1","series":null,"tags":null,"title":"skynet的网络","uri":"/posts/skynet/skynet_net/#简析"},{"categories":["skynet相关"],"content":"\rlua socket 接口 lua socket 接口代码在文件 lualib-src/lua-socket.c 中 // lualib-src/lua-socket.c 820 LUAMOD_API int 821 luaopen_skynet_socketdriver(lua_State *L) { 822 \u003e luaL_checkversion(L); 823 \u003e luaL_Reg l[] = { 824 \u003e \u003e { \"buffer\", lnewbuffer }, 825 \u003e \u003e { \"push\", lpushbuffer }, 826 \u003e \u003e { \"pop\", lpopbuffer }, 827 \u003e \u003e { \"drop\", ldrop }, 828 \u003e \u003e { \"readall\", lreadall }, 829 \u003e \u003e { \"clear\", lclearbuffer }, 830 \u003e \u003e { \"readline\", lreadline }, 831 \u003e \u003e { \"str2p\", lstr2p }, 832 \u003e \u003e { \"header\", lheader }, 833 \u003e \u003e { \"info\", linfo }, 834 835 \u003e \u003e { \"unpack\", lunpack }, 836 \u003e \u003e { NULL, NULL }, 837 \u003e }; 838 \u003e luaL_newlib(L,l); 839 \u003e luaL_Reg l2[] = { 840 \u003e \u003e { \"connect\", lconnect }, 841 \u003e \u003e { \"close\", lclose }, 842 \u003e \u003e { \"shutdown\", lshutdown }, 843 \u003e \u003e { \"listen\", llisten }, 844 \u003e \u003e { \"send\", lsend }, 845 \u003e \u003e { \"lsend\", lsendlow }, 846 \u003e \u003e { \"bind\", lbind }, 847 \u003e \u003e { \"start\", lstart }, 848 \u003e \u003e { \"pause\", lpause }, 849 \u003e \u003e { \"nodelay\", lnodelay }, 850 \u003e \u003e { \"udp\", ludp }, 851 \u003e \u003e { \"udp_connect\", ludp_connect }, 852 \u003e \u003e { \"udp_send\", ludp_send }, 853 \u003e \u003e { \"udp_address\", ludp_address }, 854 \u003e \u003e { \"resolve\", lresolve }, 855 \u003e \u003e { NULL, NULL }, 856 \u003e }; 857 \u003e lua_getfield(L, LUA_REGISTRYINDEX, \"skynet_context\"); 858 \u003e struct skynet_context *ctx = lua_touserdata(L,-1); 859 \u003e if (ctx == NULL) { 860 \u003e \u003e return luaL_error(L, \"Init skynet context first\"); 861 \u003e } 862 863 \u003e luaL_setfuncs(L,l2,1); 864 865 \u003e return 1; 866 } socket 操作为 l2 注册的 c 函数，这些函数最后都会调用 send_request 函数 // skynet-src/socket_server.c 1786 static void 1787 send_request(struct socket_server *ss, struct request_package *request, char type, int len) { 1788 request-\u003eheader[6] = (uint8_t)type; 1789 request-\u003eheader[7] = (uint8_t)len; 1790 const char * req = (const char *)request + offsetof(struct request_package, header[6]); 1791 for (;;) { 1792 ssize_t n = write(ss-\u003esendctrl_fd, req, len+2); 1793 if (n\u003c0) { 1794 if (errno != EINTR) { 1795 skynet_error(NULL, \"socket-server : send ctrl command error %s.\", strerror(errno)); 1796 } 1797 continue; 1798 } 1799 assert(n == len+2); 1800 return; 1801 } 1802 } send_request 的作用是把对应的操作及参数序列化并写入 socket sendctrl_fd 中 socket 线程那边通过监听 sendctrl_fd 获取对应 socket 操作类型及参数 ","date":"2023-11-01","objectID":"/posts/skynet/skynet_net/:0:2","series":null,"tags":null,"title":"skynet的网络","uri":"/posts/skynet/skynet_net/#lua-socket-接口"},{"categories":["skynet相关"],"content":"\rskyent 的 socket 线程 socket 线程主循环就是不断调用 socket_server_poll，主要做两件事 调用 socket_server_poll 处理 socket 调用 forward_message 把处理的结果打包发送给 lua 层 // skynet-src/skynet_socket.c 78 int- 79 skynet_socket_poll() { 80 \u003e struct socket_server *ss = SOCKET_SERVER; 81 \u003e assert(ss); 82 \u003e struct socket_message result; 83 \u003e int more = 1; 84 \u003e int type = socket_server_poll(ss, \u0026result, \u0026more); 85 \u003e switch (type) { 86 \u003e case SOCKET_EXIT: 87 \u003e \u003e return 0; 88 \u003e case SOCKET_DATA: 89 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_DATA, false, \u0026result); 90 \u003e \u003e break; 91 \u003e case SOCKET_CLOSE: 92 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_CLOSE, false, \u0026result); 93 \u003e \u003e break; 94 \u003e case SOCKET_OPEN: 95 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_CONNECT, true, \u0026result); 96 \u003e \u003e break; 97 \u003e case SOCKET_ERR: 98 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_ERROR, true, \u0026result); 99 \u003e \u003e break; 100 \u003e case SOCKET_ACCEPT: 101 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_ACCEPT, true, \u0026result); 102 \u003e \u003e break; 103 \u003e case SOCKET_UDP: 104 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_UDP, false, \u0026result); 105 \u003e \u003e break; 106 \u003e case SOCKET_WARNING: 107 \u003e \u003e forward_message(SKYNET_SOCKET_TYPE_WARNING, false, \u0026result); 108 \u003e \u003e break; 109 \u003e default: 110 \u003e \u003e skynet_error(NULL, \"Unknown socket message type %d.\",type); 111 \u003e \u003e return -1; 112 \u003e } 113 \u003e if (more) { 114 \u003e \u003e return -1; 115 \u003e } 116 \u003e return 1; 117 } socket_server_pool 主要做两件事情 调用 has_cmd 函数检查 sendctrl_fd 是否有事件，如果有就调用 ctrl_cmd 根据操作类型进行对应处理（如 “B” 对应 bind，“L” 对应 listen， “K” 对应 close 等） 调用 epoll_wait 获取监听 socket 的事件，并对应处理（ 1726 ~1771） 1671 int- 1672 socket_server_poll(struct socket_server *ss, struct socket_message * result, int * more) { 1673 \u003e for (;;) { 1674 \u003e \u003e if (ss-\u003echeckctrl) { 1675 \u003e \u003e \u003e if (has_cmd(ss)) { 1676 \u003e \u003e \u003e \u003e int type = ctrl_cmd(ss, result); 1677 \u003e \u003e \u003e \u003e if (type != -1) { 1678 \u003e \u003e \u003e \u003e \u003e clear_closed_event(ss, result, type); 1679 \u003e \u003e \u003e \u003e \u003e return type; 1680 \u003e \u003e \u003e \u003e } else 1681 \u003e \u003e \u003e \u003e \u003e continue; 1682 \u003e \u003e \u003e } else { 1683 \u003e \u003e \u003e \u003e ss-\u003echeckctrl = 0; 1684 \u003e \u003e \u003e } 1685 \u003e \u003e } 1686 \u003e \u003e if (ss-\u003eevent_index == ss-\u003eevent_n) { 1687 \u003e \u003e \u003e ss-\u003eevent_n = sp_wait(ss-\u003eevent_fd, ss-\u003eev, MAX_EVENT); 1688 \u003e \u003e \u003e ss-\u003echeckctrl = 1; 1689 \u003e \u003e \u003e if (more) { 1690 \u003e \u003e \u003e \u003e *more = 0; 1691 \u003e \u003e \u003e } 1692 \u003e \u003e \u003e ss-\u003eevent_index = 0; 1693 \u003e \u003e \u003e if (ss-\u003eevent_n \u003c= 0) { 1694 \u003e \u003e \u003e \u003e ss-\u003eevent_n = 0; 1695 \u003e \u003e \u003e \u003e int err = errno; 1696 \u003e \u003e \u003e \u003e if (err != EINTR) { 1697 \u003e \u003e \u003e \u003e \u003e skynet_error(NULL, \"socket-server: %s\", strerror(err)); 1698 \u003e \u003e \u003e \u003e } 1699 \u003e \u003e \u003e \u003e continue; 1700 \u003e \u003e \u003e } 1701 \u003e \u003e } ... 1726 \u003e \u003e default: 1727 \u003e \u003e \u003e if (e-\u003eread) { 1728 \u003e \u003e \u003e \u003e int type; 1729 \u003e \u003e \u003e \u003e if (s-\u003eprotocol == PROTOCOL_TCP) { 1730 \u003e \u003e \u003e \u003e \u003e type = forward_message_tcp(ss, s, \u0026l, result); 1731 \u003e \u003e \u003e \u003e \u003e if (type == SOCKET_MORE) { 1732 \u003e \u003e \u003e \u003e \u003e \u003e --ss-\u003eevent_index; 1733 \u003e \u003e \u003e \u003e \u003e \u003e return SOCKET_DATA; 1734 \u003e \u003e \u003e \u003e \u003e } 1735 \u003e \u003e \u003e \u003e } else { 1736 \u003e \u003e \u003e \u003e \u003e type = forward_message_udp(ss, s, \u0026l, result); 1737 \u003e \u003e \u003e \u003e \u003e if (type == SOCKET_UDP) { 1738 \u003e \u003e \u003e \u003e \u003e \u003e // try read again 1739 \u003e \u003e \u003e \u003e \u003e \u003e --ss-\u003eevent_index; 1740 \u003e \u003e \u003e \u003e \u003e \u003e return SOCKET_UDP; 1741 \u003e \u003e \u003e \u003e \u003e } 1742 \u003e \u003e \u003e \u003e } 1743 \u003e \u003e \u003e \u003e if (e-\u003ewrite \u0026\u0026 type != SOCKET_CLOSE \u0026\u0026 type != SOCKET_ERR) { 1744 \u003e \u003e \u003e \u003e \u003e // Try to dispatch write message next step if write flag set. 1745 \u003e \u003e \u003e \u003e \u003e e-\u003eread = false; 1746 \u003e \u003e \u003e \u003e \u003e --ss-\u003eevent_index; 1747 \u003e \u003e \u003e \u003e } 1748 \u003e \u003e \u003e \u003e if (type == -1) 1749 \u003e \u003e \u003e \u003e \u003e break;\u003e \u003e \u003e \u003e 1750 \u003e \u003e \u003e \u003e return type; 1751 \u003e \u003e \u003e } 1752 \u003e \u003e \u003e if (e-\u003ewrite) { 1753 \u003e \u003e \u003e \u003e int type = send_buffer(ss, s, \u0026l, result); 1754 \u003e \u003e \u003e \u003e if (type == -1) 1755 \u003e \u003e \u003e \u003e \u003e break; 1756 \u003e \u003e \u003e \u003e return type; 1757 \u003e \u003e \u003e } 1758 \u003e \u003e \u003e if (e-\u003eerror) { 1759 \u003e \u003e \u003e \u003e int error; 1760 \u003e \u003e \u003e \u003e socklen_t len = sizeof(error);-- 1761 \u003e \u003e \u003e \u003e int code = getsockopt(s-\u003efd, SOL_SOCKET, SO_ERROR, \u0026error, \u0026len);-- 1762 \u003e \u003e \u003e \u003e const char * err = NULL; 1763 \u003e \u003e \u003e \u003e if (code \u003c 0) { 1764 \u003e \u003e \u003e \u003e \u003e err = strerror(errno); 1765 \u003e \u003e \u003e \u003e } else if (error != 0) { 1766 \u003e \u003e \u003e \u003e \u003e err = strerror(error); 1767 \u003e \u003e \u003e \u003e } else { 1768 \u003e \u003e \u003e \u003e \u003e err = \"Unknown error\"; 1769 \u003e \u003e \u003e \u003e }","date":"2023-11-01","objectID":"/posts/skynet/skynet_net/:0:3","series":null,"tags":null,"title":"skynet的网络","uri":"/posts/skynet/skynet_net/#skyent-的-socket-线程"},{"categories":["skynet相关"],"content":"\rskynet 中 c 端绑定 lua 函数的做法\r简述 创建新的 userdata 创建一个新 thread 对象，把 callback function 至于这个 thread 中 把新 thread 绑定 userdata 的 uservalue 上（防止 gc） userdata 的 C 指针放到 C 端，用于 callback 调用 callback function 放到新 thead 中而不是注册表中是因为这样做比从注册表中读会 callback function 要高效 代码分析 122 static int 123 lcallback(lua_State *L) { 124 \u003e struct skynet_context * context = lua_touserdata(L, lua_upvalueindex(1)); 125 \u003e int forward = lua_toboolean(L, 2); // 获取第二个参数 126 \u003e luaL_checktype(L,1,LUA_TFUNCTION); // 检查第一个参数是否是 lua function 127 \u003e lua_settop(L,1); // 弹出除第一个参数外的所有参数，即 lua function 在 L 的栈底 128 \u003e struct callback_context * cb_ctx = (struct callback_context *)lua_newuserdatauv(L, sizeof(*cb_ctx), 2); // 创建 userdata callback_context 并压入到 L 的栈中 129 \u003e cb_ctx-\u003eL = lua_newthread(L); // 创建一个新线程并压入 L 的栈中 130 \u003e lua_pushcfunction(cb_ctx-\u003eL, traceback); // 将 c 函数 traceback 压入新线程的栈中 131 \u003e lua_setiuservalue(L, -2, 1); // 将新线程弹出并设置为 128 创建的 userdata 的 uservalue 132 \u003e lua_getfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将注册表下标为 \"callback_context\" 的值压入 L 的栈中 133 \u003e lua_setiuservalue(L, -2, 2); // 将上面压入的值设置为 128 创建的 userdata 的 uservalue 134 \u003e lua_setfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将 128 创建的 userdata 设置为注册表下标为 \"callback_context\" 的值 135 \u003e lua_xmove(L, cb_ctx-\u003eL, 1); // 将 userdata 从 L 中弹出并压入新线程中 136 137 \u003e skynet_callback(context, cb_ctx, (forward)?(_forward_pre):(_cb_pre)); // 将 _cb_pre/_forward_pre 设置为 context 的 callback，两种区别为是否自动释放 skynet msg 的空间 138 \u003e return 0; 139 } 第132~133行把旧的 userdata 设置为新 userdata 的 uservalue，是因为在重新设置 callback 时，如果直接替换掉旧的 userdata 时，这只旧 userdata 就处于可被 gc 的状态，如果此时触发 gc 行为，将会导致当前正在被执行的 coroutine 和 cb_ctx 被回收掉，从而导致crash。具体如下：skynet callback导致的crash问题 Lua binding 中正确的 callback ","date":"2023-09-19","objectID":"/posts/skynet/skynet_cb/:1:0","series":null,"tags":null,"title":"skynet的callback","uri":"/posts/skynet/skynet_cb/#skynet-中-c-端绑定-lua-函数的做法"},{"categories":["skynet相关"],"content":"\rskynet 中 c 端绑定 lua 函数的做法\r简述 创建新的 userdata 创建一个新 thread 对象，把 callback function 至于这个 thread 中 把新 thread 绑定 userdata 的 uservalue 上（防止 gc） userdata 的 C 指针放到 C 端，用于 callback 调用 callback function 放到新 thead 中而不是注册表中是因为这样做比从注册表中读会 callback function 要高效 代码分析 122 static int 123 lcallback(lua_State *L) { 124 \u003e struct skynet_context * context = lua_touserdata(L, lua_upvalueindex(1)); 125 \u003e int forward = lua_toboolean(L, 2); // 获取第二个参数 126 \u003e luaL_checktype(L,1,LUA_TFUNCTION); // 检查第一个参数是否是 lua function 127 \u003e lua_settop(L,1); // 弹出除第一个参数外的所有参数，即 lua function 在 L 的栈底 128 \u003e struct callback_context * cb_ctx = (struct callback_context *)lua_newuserdatauv(L, sizeof(*cb_ctx), 2); // 创建 userdata callback_context 并压入到 L 的栈中 129 \u003e cb_ctx-\u003eL = lua_newthread(L); // 创建一个新线程并压入 L 的栈中 130 \u003e lua_pushcfunction(cb_ctx-\u003eL, traceback); // 将 c 函数 traceback 压入新线程的栈中 131 \u003e lua_setiuservalue(L, -2, 1); // 将新线程弹出并设置为 128 创建的 userdata 的 uservalue 132 \u003e lua_getfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将注册表下标为 \"callback_context\" 的值压入 L 的栈中 133 \u003e lua_setiuservalue(L, -2, 2); // 将上面压入的值设置为 128 创建的 userdata 的 uservalue 134 \u003e lua_setfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将 128 创建的 userdata 设置为注册表下标为 \"callback_context\" 的值 135 \u003e lua_xmove(L, cb_ctx-\u003eL, 1); // 将 userdata 从 L 中弹出并压入新线程中 136 137 \u003e skynet_callback(context, cb_ctx, (forward)?(_forward_pre):(_cb_pre)); // 将 _cb_pre/_forward_pre 设置为 context 的 callback，两种区别为是否自动释放 skynet msg 的空间 138 \u003e return 0; 139 } 第132~133行把旧的 userdata 设置为新 userdata 的 uservalue，是因为在重新设置 callback 时，如果直接替换掉旧的 userdata 时，这只旧 userdata 就处于可被 gc 的状态，如果此时触发 gc 行为，将会导致当前正在被执行的 coroutine 和 cb_ctx 被回收掉，从而导致crash。具体如下：skynet callback导致的crash问题 Lua binding 中正确的 callback ","date":"2023-09-19","objectID":"/posts/skynet/skynet_cb/:1:0","series":null,"tags":null,"title":"skynet的callback","uri":"/posts/skynet/skynet_cb/#简述"},{"categories":["skynet相关"],"content":"\rskynet 中 c 端绑定 lua 函数的做法\r简述 创建新的 userdata 创建一个新 thread 对象，把 callback function 至于这个 thread 中 把新 thread 绑定 userdata 的 uservalue 上（防止 gc） userdata 的 C 指针放到 C 端，用于 callback 调用 callback function 放到新 thead 中而不是注册表中是因为这样做比从注册表中读会 callback function 要高效 代码分析 122 static int 123 lcallback(lua_State *L) { 124 \u003e struct skynet_context * context = lua_touserdata(L, lua_upvalueindex(1)); 125 \u003e int forward = lua_toboolean(L, 2); // 获取第二个参数 126 \u003e luaL_checktype(L,1,LUA_TFUNCTION); // 检查第一个参数是否是 lua function 127 \u003e lua_settop(L,1); // 弹出除第一个参数外的所有参数，即 lua function 在 L 的栈底 128 \u003e struct callback_context * cb_ctx = (struct callback_context *)lua_newuserdatauv(L, sizeof(*cb_ctx), 2); // 创建 userdata callback_context 并压入到 L 的栈中 129 \u003e cb_ctx-\u003eL = lua_newthread(L); // 创建一个新线程并压入 L 的栈中 130 \u003e lua_pushcfunction(cb_ctx-\u003eL, traceback); // 将 c 函数 traceback 压入新线程的栈中 131 \u003e lua_setiuservalue(L, -2, 1); // 将新线程弹出并设置为 128 创建的 userdata 的 uservalue 132 \u003e lua_getfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将注册表下标为 \"callback_context\" 的值压入 L 的栈中 133 \u003e lua_setiuservalue(L, -2, 2); // 将上面压入的值设置为 128 创建的 userdata 的 uservalue 134 \u003e lua_setfield(L, LUA_REGISTRYINDEX, \"callback_context\"); // 将 128 创建的 userdata 设置为注册表下标为 \"callback_context\" 的值 135 \u003e lua_xmove(L, cb_ctx-\u003eL, 1); // 将 userdata 从 L 中弹出并压入新线程中 136 137 \u003e skynet_callback(context, cb_ctx, (forward)?(_forward_pre):(_cb_pre)); // 将 _cb_pre/_forward_pre 设置为 context 的 callback，两种区别为是否自动释放 skynet msg 的空间 138 \u003e return 0; 139 } 第132~133行把旧的 userdata 设置为新 userdata 的 uservalue，是因为在重新设置 callback 时，如果直接替换掉旧的 userdata 时，这只旧 userdata 就处于可被 gc 的状态，如果此时触发 gc 行为，将会导致当前正在被执行的 coroutine 和 cb_ctx 被回收掉，从而导致crash。具体如下：skynet callback导致的crash问题 Lua binding 中正确的 callback ","date":"2023-09-19","objectID":"/posts/skynet/skynet_cb/:1:0","series":null,"tags":null,"title":"skynet的callback","uri":"/posts/skynet/skynet_cb/#代码分析"},{"categories":["其他"],"content":" 段表 保存ELF文件各段的基本属性的结构，记录包括段名，段长度，在文件中的偏移量以及读写权限和段的其他属性 代码段 程序源代码编译后的机器指令存放位置，在文件中占用一定大小，该区域通常为只读 数据段（.data段） 保存已经初始化了的全局静态变量和局部静态变量，在文件中占用一定大小 .bss段 存放未初始化的全局变量和局部静态变量，在文件中不占大小（节省磁盘空间），程序运行前才会开辟空间，已经初始化的变量也可能因为编译器的优化而存放在该段（比如初始化值为0），该段大小（所有未初始化的变量总大小）记录在段表里，符号表里会记录各变量的位置 符号表 记录目标文件中所用到的所有符号（包括定义在目标文件中的全局符号，在本目标文件中引用的全局符号，段名，局部符号，行号信息等） 问题：ELF是什么？其大小与程序中全局变量的是否初始化有什么关系ELF为目标文件（linux下），未初始化的全局变量会保存在.bss段，而.bss段在ELF文件中并不占用大小。 ","date":"2021-11-15","objectID":"/posts/other/elf%E6%96%87%E4%BB%B6/:0:0","series":null,"tags":null,"title":"ELF文件","uri":"/posts/other/elf%E6%96%87%E4%BB%B6/#"},{"categories":["其他"],"content":" 段表 保存ELF文件各段的基本属性的结构，记录包括段名，段长度，在文件中的偏移量以及读写权限和段的其他属性 代码段 程序源代码编译后的机器指令存放位置，在文件中占用一定大小，该区域通常为只读 数据段（.data段） 保存已经初始化了的全局静态变量和局部静态变量，在文件中占用一定大小 .bss段 存放未初始化的全局变量和局部静态变量，在文件中不占大小（节省磁盘空间），程序运行前才会开辟空间，已经初始化的变量也可能因为编译器的优化而存放在该段（比如初始化值为0），该段大小（所有未初始化的变量总大小）记录在段表里，符号表里会记录各变量的位置 符号表 记录目标文件中所用到的所有符号（包括定义在目标文件中的全局符号，在本目标文件中引用的全局符号，段名，局部符号，行号信息等） 问题：ELF是什么？其大小与程序中全局变量的是否初始化有什么关系ELF为目标文件（linux下），未初始化的全局变量会保存在.bss段，而.bss段在ELF文件中并不占用大小。 ","date":"2021-11-15","objectID":"/posts/other/elf%E6%96%87%E4%BB%B6/:0:0","series":null,"tags":null,"title":"ELF文件","uri":"/posts/other/elf%E6%96%87%E4%BB%B6/#问题elf是什么其大小与程序中全局变量的是否初始化有什么关系"},{"categories":["其他"],"content":"\rGit配置 设置名称： git config –global user.name “名称” 设置邮箱： git config –global user.email “邮箱” 查看设置： git config –global –list ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#git配置"},{"categories":["其他"],"content":"\rGit配置 设置名称： git config –global user.name “名称” 设置邮箱： git config –global user.email “邮箱” 查看设置： git config –global –list ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#设置名称"},{"categories":["其他"],"content":"\rGit配置 设置名称： git config –global user.name “名称” 设置邮箱： git config –global user.email “邮箱” 查看设置： git config –global –list ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#设置邮箱"},{"categories":["其他"],"content":"\rGit配置 设置名称： git config –global user.name “名称” 设置邮箱： git config –global user.email “邮箱” 查看设置： git config –global –list ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#查看设置"},{"categories":["其他"],"content":"\rGit分支操作 新建分支： git branch 分支名 git checkout -b 分支名 切换分支： git checkout 分支名 删除分支： git branch -D 分支名 合并分支 git merge 分支名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#git分支操作"},{"categories":["其他"],"content":"\rGit分支操作 新建分支： git branch 分支名 git checkout -b 分支名 切换分支： git checkout 分支名 删除分支： git branch -D 分支名 合并分支 git merge 分支名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#新建分支"},{"categories":["其他"],"content":"\rGit分支操作 新建分支： git branch 分支名 git checkout -b 分支名 切换分支： git checkout 分支名 删除分支： git branch -D 分支名 合并分支 git merge 分支名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#切换分支"},{"categories":["其他"],"content":"\rGit分支操作 新建分支： git branch 分支名 git checkout -b 分支名 切换分支： git checkout 分支名 删除分支： git branch -D 分支名 合并分支 git merge 分支名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#删除分支"},{"categories":["其他"],"content":"\rGit分支操作 新建分支： git branch 分支名 git checkout -b 分支名 切换分支： git checkout 分支名 删除分支： git branch -D 分支名 合并分支 git merge 分支名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#合并分支"},{"categories":["其他"],"content":"\rGit基本工作流程 添加文件到暂存区(staging area)： git add 文件名 将暂存区文件添加到仓库(local repository)中： git commit -m “提交信息” 上传远程代码(remote repository)并合并： git push -u origin 分支名 下载远程代码并合并 git pull ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#git基本工作流程"},{"categories":["其他"],"content":"\rGit基本工作流程 添加文件到暂存区(staging area)： git add 文件名 将暂存区文件添加到仓库(local repository)中： git commit -m “提交信息” 上传远程代码(remote repository)并合并： git push -u origin 分支名 下载远程代码并合并 git pull ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#添加文件到暂存区staging-area"},{"categories":["其他"],"content":"\rGit基本工作流程 添加文件到暂存区(staging area)： git add 文件名 将暂存区文件添加到仓库(local repository)中： git commit -m “提交信息” 上传远程代码(remote repository)并合并： git push -u origin 分支名 下载远程代码并合并 git pull ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#将暂存区文件添加到仓库local-repository中"},{"categories":["其他"],"content":"\rGit基本工作流程 添加文件到暂存区(staging area)： git add 文件名 将暂存区文件添加到仓库(local repository)中： git commit -m “提交信息” 上传远程代码(remote repository)并合并： git push -u origin 分支名 下载远程代码并合并 git pull ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#上传远程代码remote-repository并合并"},{"categories":["其他"],"content":"\rGit基本工作流程 添加文件到暂存区(staging area)： git add 文件名 将暂存区文件添加到仓库(local repository)中： git commit -m “提交信息” 上传远程代码(remote repository)并合并： git push -u origin 分支名 下载远程代码并合并 git pull ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#下载远程代码并合并"},{"categories":["其他"],"content":"\rGit暂存区文件操作 使用暂存区指定文件覆盖工作区对应文件： git checkout 文件名 删除暂存区文件（工作区不做改变）： git rm –cached 文件名 回滚暂存区对应文件到当前版本： git reset HEAD 文件名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#git暂存区文件操作"},{"categories":["其他"],"content":"\rGit暂存区文件操作 使用暂存区指定文件覆盖工作区对应文件： git checkout 文件名 删除暂存区文件（工作区不做改变）： git rm –cached 文件名 回滚暂存区对应文件到当前版本： git reset HEAD 文件名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#使用暂存区指定文件覆盖工作区对应文件"},{"categories":["其他"],"content":"\rGit暂存区文件操作 使用暂存区指定文件覆盖工作区对应文件： git checkout 文件名 删除暂存区文件（工作区不做改变）： git rm –cached 文件名 回滚暂存区对应文件到当前版本： git reset HEAD 文件名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#删除暂存区文件工作区不做改变"},{"categories":["其他"],"content":"\rGit暂存区文件操作 使用暂存区指定文件覆盖工作区对应文件： git checkout 文件名 删除暂存区文件（工作区不做改变）： git rm –cached 文件名 回滚暂存区对应文件到当前版本： git reset HEAD 文件名 ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#回滚暂存区对应文件到当前版本"},{"categories":["其他"],"content":"\rGit远端交互 列出所有remote： git remote -v 添加远端： git remote add xxx 删除远端关联： git remote remove xxx ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#git远端交互"},{"categories":["其他"],"content":"\rGit远端交互 列出所有remote： git remote -v 添加远端： git remote add xxx 删除远端关联： git remote remove xxx ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#列出所有remote"},{"categories":["其他"],"content":"\rGit远端交互 列出所有remote： git remote -v 添加远端： git remote add xxx 删除远端关联： git remote remove xxx ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#添加远端"},{"categories":["其他"],"content":"\rGit远端交互 列出所有remote： git remote -v 添加远端： git remote add xxx 删除远端关联： git remote remove xxx ","date":"2021-10-27","objectID":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"Git基本操作","uri":"/posts/other/git%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#删除远端关联"},{"categories":["redis"],"content":"\rredis主从库模式 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:0:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#redis主从库模式"},{"categories":["redis"],"content":"\rredis高可靠性 高可靠性包含两层含义：数据尽量少丢失，服务尽量少中断 前者使用AOF和RDB可以保证 后者使用主从库模式保证 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:1:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#redis高可靠性"},{"categories":["redis"],"content":"\r读写分离 读操作：主库、从库都可以接收 写操作：⾸先到主库执⾏，然后，主库将写操作同步给从库 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:2:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#读写分离"},{"categories":["redis"],"content":"\r一致性问题 redis在主从数据库之间的复制是异步的，这意味着，主数据库执行完客户端请求的命令后会立即将命令发送给请求的客户端，并同步到从数据库，而不会等待从数据库接收到命令后再返回给客户端，因此该情况就会存在一定的数据不一致性风险，也就是redis不保证强一致性，而是通过从库策略追赶与主数据库的数据差异，以保障主从状态一致 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:3:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#一致性问题"},{"categories":["redis"],"content":"\r全量复制（主从库第一次同步） ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:0:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#全量复制主从库第一次同步"},{"categories":["redis"],"content":"\r同步过程 从库通过replicaof命令，向主库发送psync命令（参数runID为主库id，offset为复制进度） 主库收到psync命令后，返回FULLRESYNC响应命令（参数为主库runID和主库⽬前的复制进度 offset），主从库开始同步 主库执⾏bgsave命令，⽣成RDB⽂件，接着将⽂件发给从库，从库接收文件后清空当前数据库，加载RDB文件 主库同步RDB文件并不会阻塞，会将期间的写请求记录在专⻔的replication buffer 主库完成RDB文件发送后，会把replication buffer中的修改操作发给从库，从库执行这些操作后就完成了数据同步 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:1:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#同步过程"},{"categories":["redis"],"content":"\r主从级联模式（“主-从-从”模式） 多个从库连接到同一主库，会导致主库压力增大（主要是fork子进程会阻塞主线程，传输RDB文件会占用主库网络带宽），此时可以使用主从级联模式 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:2:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#主从级联模式主-从-从模式"},{"categories":["redis"],"content":"\rRDB文件是否落盘 Redis在全量复制时，既支持先生成RDB文件，再把RDB文件传给从库，也支持在主库上直接通过socket把数据传给从库，这称为无盘复制 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:3:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#rdb文件是否落盘"},{"categories":["redis"],"content":"\r基于长连接的命令传播​ 一旦主从库完成全量复制，他们之间会维护一个网络连接，主库通过该连接把接受到的命令操作同步给从库，避免频繁建立连接的开销 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:0:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#基于长连接的命令传播"},{"categories":["redis"],"content":"\r增量复制 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:0:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#增量复制"},{"categories":["redis"],"content":"\r使用场景 网络断连或阻塞会导致主从库无法进行命令传播，而重新进行一次全量复制开销过大，此时主从库使用增量复制同步数据 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:1:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#使用场景"},{"categories":["redis"],"content":"\r同步过程 主从库断开后，主库会把期间收到的写操作命令写入replication buff和repl_backlog_buffer缓冲区中 repl_backlog_buffer是一个环形缓冲区，slave_repl_offset为从库下标，master_repl_offset为主库下标 主从库连接恢复后，从库首先发送psync命令，并把自己当前的slave_repl_offset发给主库 主库把处于master_repl_offset和slave_repl_offset之间的命令操作同步给从库完成同步 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:2:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#同步过程-1"},{"categories":["redis"],"content":"\rrepl_backlog_buffer缓冲区 由于repl_back_log_buffer是一个环形缓冲区，当主从库读取速度差异过大有可能导致从库未读的操作被主库的新写操作覆盖，造成主从库数据不一致 缓冲空间⼤⼩ = 主库写⼊命令速度 * 操作⼤⼩ - 主从库间 ⽹络传输命令速度 * 操作⼤⼩，实际应用中考虑其他突发情况，通常把这个缓冲空间扩大一倍 可以考虑使用切片集群分担单个主库的请求压力 repl_backlog_buffer是所有从库共享的 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:3:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#repl_backlog_buffer缓冲区"},{"categories":["redis"],"content":"\r断线重连后同步选择 由于repl_backlog_buffer存在覆盖的情况，重连后主库会根据从库的slave_repl_offset选择全量复制还是增量复制 ","date":"2021-08-10","objectID":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/:4:0","series":null,"tags":null,"title":"Redis主从库数据同步","uri":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%BA%93%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/#断线重连后同步选择"},{"categories":["redis"],"content":"\rAOF日志 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:0:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#aof日志"},{"categories":["redis"],"content":"\rAOF日志实现 AOF日志记录的是redis收到的操作命令，以文本形式保存，由主线程写回 AOF日志采用先执⾏命令再记⽇志的方式（为避免额外的检查开销，不阻塞当前写操作） 用AOF方法进行故障恢复时，需要逐一把操作日志都执行一遍 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:1:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#aof日志实现"},{"categories":["redis"],"content":"\r三种回写策略 Always，同步写回：每次执行写操作后立马同步将日志写回磁盘 Everysec，每秒写回：先把日志写到AOF文件的内存缓冲区，每隔一秒将缓冲区的内容写回磁盘 No，操作系统控制写回：先把日志写到AOF文件的内存缓冲区，有操作系统决定写回时机 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:2:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#三种回写策略"},{"categories":["redis"],"content":"\r三种回写策略的优劣 写回方式 写回时机 优点 缺点 Always 同步写回 可靠度高，数据基本不会丢失 每次写操作都要落盘，性能影响较大 Everysec 每秒写回 性能适中 宕机时丢失1s内的数据 No 系统控制写回 性能好 宕机会丢失较多数据 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:3:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#三种回写策略的优劣"},{"categories":["redis"],"content":"\rAOF重写机制 主线程fork重写子进程，子进程将新的内容写到临时文件中 重写并不阻塞主线程，主线程对于新的写入操作，一边将他们累积到内存缓冲中，一边追加到现有的AOF文件中（避免重写时宕机引起数据丢失） 子进程完成重写后发送信号给父进程，父进程接收信号后将内存缓存中的所有内容追加到新的AOF文件中（阻塞） 最后redis原子地用新文件替换旧文件，之后的命令将直接追加到新的AOF文件末尾 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:4:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#aof重写机制"},{"categories":["redis"],"content":"\r内存快照 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:0:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#内存快照"},{"categories":["redis"],"content":"\rRedis提供了两个命令来⽣成RDB⽂件，分别是save和bgsave save：在主线程中执行，会导致阻塞 bgsave：创建子线程专门用于写入RDB文件，避免主线程阻塞，是redis默认配置 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:1:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#redis提供了两个命令来成rdb件分别是save和bgsave"},{"categories":["redis"],"content":"\r快照原理（利用copy-on-write原理） 主线程fork⽣成bgsave⼦进程，两者共享同一物理内存，子线程将redis内存中的数据全量记录到磁盘文件中，该快照文件成为RDB文件 主线程对数据进行写操作时，会将该部分内存复制一份副本（写时复制），主线程可直接修改原来的数据而不用担心子进程的数据污染问题 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:2:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#快照原理利用copy-on-write原理"},{"categories":["redis"],"content":"\r快照优劣 优：可以快速恢复数据库（避免了AOF需要顺序，逐一执行命令带来的低效性能的问题） 劣：频繁的快照会造成性能的消耗，主要是将全量数据写入磁盘的消耗和主线程进行fork操作的消耗 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:3:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#快照优劣"},{"categories":["redis"],"content":"\r总结 数据不能丢失时，内存快照和AOF的混合使⽤是⼀个很好的选择 如果允许分钟级别的数据丢失，可以只使⽤RDB 如果只⽤AOF，优先使⽤everysec的配置选项，因为它在可靠性和性能之间取了⼀个平衡 ","date":"2021-07-26","objectID":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/:0:0","series":null,"tags":null,"title":"Redis持久化","uri":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/#总结"},{"categories":["其他"],"content":"\rCenos8安装json-c库 先把文件从https://github.com/json-c/json-c克隆到本地目录 进入json-c目录分别执行cmake ./，sudo make install（cmake要先下好） 安装完成后查看一下/usr/local/include目录下是否有json-c目录（没有就是安装的时候没给权限导致复制失败） 查看/usr/local/lib目录或者/usr/local/lib64目录下是否有json-c的动态库文件（没有的话应该时安装有问题） 添加动态路的路径：sudo vim /etc/ld.so.conf添加/usr/local/lib或者/usr/local/lib64（根据上一步的目录） 用 sudo ldconfig更新文件/etc/ld.so.conf的修改生效 使用时要包含json.h头文件，编译时需要加上-ljson-c（我看网上的都是-json的，这个应该是要看动态库的名称确定吧） 安装时遇到的问题 没有安装cmake工具导致执行cmake命令时出现问题（cmake的版本也要确定一下） 使用-json-c编译导致编译失败 make install时没给权限导致install失败（安装时弹了一个error，没仔细看出来） 没有添加动态库的加载路径，导致执行文件时会报错找不到动态库文件，用ldd查看一下是libjson-c.so.5文件没找到，加了路径记得要sudo ldconfig更新一下不然还是不生效的 ","date":"2021-01-26","objectID":"/posts/other/centos8%E5%AE%89%E8%A3%85json-c%E5%BA%93/:0:0","series":null,"tags":null,"title":"CentOS8安装json C库","uri":"/posts/other/centos8%E5%AE%89%E8%A3%85json-c%E5%BA%93/#"},{"categories":["其他"],"content":"\rCenos8安装json-c库 先把文件从https://github.com/json-c/json-c克隆到本地目录 进入json-c目录分别执行cmake ./，sudo make install（cmake要先下好） 安装完成后查看一下/usr/local/include目录下是否有json-c目录（没有就是安装的时候没给权限导致复制失败） 查看/usr/local/lib目录或者/usr/local/lib64目录下是否有json-c的动态库文件（没有的话应该时安装有问题） 添加动态路的路径：sudo vim /etc/ld.so.conf添加/usr/local/lib或者/usr/local/lib64（根据上一步的目录） 用 sudo ldconfig更新文件/etc/ld.so.conf的修改生效 使用时要包含json.h头文件，编译时需要加上-ljson-c（我看网上的都是-json的，这个应该是要看动态库的名称确定吧） 安装时遇到的问题 没有安装cmake工具导致执行cmake命令时出现问题（cmake的版本也要确定一下） 使用-json-c编译导致编译失败 make install时没给权限导致install失败（安装时弹了一个error，没仔细看出来） 没有添加动态库的加载路径，导致执行文件时会报错找不到动态库文件，用ldd查看一下是libjson-c.so.5文件没找到，加了路径记得要sudo ldconfig更新一下不然还是不生效的 ","date":"2021-01-26","objectID":"/posts/other/centos8%E5%AE%89%E8%A3%85json-c%E5%BA%93/:0:0","series":null,"tags":null,"title":"CentOS8安装json C库","uri":"/posts/other/centos8%E5%AE%89%E8%A3%85json-c%E5%BA%93/#cenos8安装json-c库"},{"categories":["其他"],"content":" 命令 含义/用法 start 开始调试,停在第一行代码处 (gdb) start l(list) 查看源代码 (gdb) l \u003cnumber/function\u003e b(breakpoint) 设置断点 (gdb) b \u003c行号/函数名\u003eb … if i == 3：条件断点 info info breakpoints：显示所有断点 info stack：查看堆栈信息 info args：查看当前参数值 info frame：输出栈帧的使用情况 info locals：查看局部变量 s(step) 执行一行源程序代码，如果此行代码中有函数调用，则进入该函数 (gdb) s n(next) 执行一行源程序代码，此行代码中的函数调用也一并执行 (gdb) n r(run) 运行被调试的程序 (gdb) r c(continue) 继续执行被调试程序，直至下一个断点或程序结束 (gdb) c finish 函数结束 p(print) 显示指定变量的值 (gdb) p \u003c变量名\u003e set args name=v 可指定运行时参数。(gdb) set args 10 20 show args 查看运行时参数 q(quit) 退出GDB调试环境 (gdb) q bt(backtrack) 查看函数堆栈 (gdb) bt f(frame) 切换当前栈 (gdb) f \u003c栈序号\u003e u(until) 结束当前循环 (gdb) until set variable 给变量赋值 jump 在源代码的另一段开始运行 delete 删除断点 (gdb) delete \u003c断点号\u003e watch 变量变化时暂停运行 awatch 变量被访问、改变是暂停执行 rwatch 变量被访问时暂停执行 disp(display) 跟踪查看某个变量,每次停下来都显示它的值 k(kill) 终止正在调试的程序 ","date":"2021-01-15","objectID":"/posts/other/gdb%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:0","series":null,"tags":null,"title":"GDB基本操作","uri":"/posts/other/gdb%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/#"},{"categories":["其他"],"content":"\r一、阻塞IO（blocking I/O） io两个阶段： 等待数据准备 将数据从内核拷贝到进程中 调用recvfrom后调用进程/线程阻塞直到内核把数据准备好并把数据拷贝到用户内存后，内核返回结果，调用进程/线程的阻塞状态解除，继续运行（阻塞io） 实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的 ","date":"2020-09-03","objectID":"/posts/other/io%E6%A8%A1%E5%9E%8B/:0:0","series":null,"tags":null,"title":"Io模型","uri":"/posts/other/io%E6%A8%A1%E5%9E%8B/#一阻塞ioblocking-io"},{"categories":["其他"],"content":"\r二、非阻塞IO（noblocking I/O） 调用recvfrom后直接返回结果，若内核数据并没有准备好则返回error。 在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有（这种方法会导致cpu占用率大幅上升） 与阻塞io的主要差异是调用接口后立即返回调用结果而不是阻塞调用方直到内核返回结果。 Linux下，可以通过设置socket使其变为non-blocking ","date":"2020-09-03","objectID":"/posts/other/io%E6%A8%A1%E5%9E%8B/:0:0","series":null,"tags":null,"title":"Io模型","uri":"/posts/other/io%E6%A8%A1%E5%9E%8B/#二非阻塞ionoblocking-io"},{"categories":["其他"],"content":"\r三、多路复用IO（IO multiplexing） select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程 当用户进程调用了select，process会阻塞在select上而不是单个io操作上，而同时，kernel会“监视”所有select负责的socket，当任何一个socket的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 ","date":"2020-09-03","objectID":"/posts/other/io%E6%A8%A1%E5%9E%8B/:0:0","series":null,"tags":null,"title":"Io模型","uri":"/posts/other/io%E6%A8%A1%E5%9E%8B/#三多路复用ioio-multiplexing"},{"categories":["其他"],"content":"\r四、异步IO（Asynchronous I/O） 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 真正的异步io（全过程并没有被阻塞，其他四种可能阻塞在数据准备阶段或者数据复制阶段）。 ","date":"2020-09-03","objectID":"/posts/other/io%E6%A8%A1%E5%9E%8B/:0:0","series":null,"tags":null,"title":"Io模型","uri":"/posts/other/io%E6%A8%A1%E5%9E%8B/#四异步ioasynchronous-io"},{"categories":["其他"],"content":"\r信号驱动IO（signal driven I/O， SIGIO） 首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。当数据报准备好读取时，内核就为该进程产生一个SIGIO信号。我们随后既可以在信号处理函数中调用recvfrom读取数据报，并通知主循环数据已准备好待处理，也可以立即通知主循环，让它来读取数据报。无论如何处理SIGIO信号，这种模型的优势在于等待数据报到达(第一阶段)期间，进程可以继续执行，不被阻塞。免去了select的阻塞与轮询，当有活跃套接字时，由注册的handler处理。 阻塞在数据复制阶段。 ","date":"2020-09-03","objectID":"/posts/other/io%E6%A8%A1%E5%9E%8B/:0:0","series":null,"tags":null,"title":"Io模型","uri":"/posts/other/io%E6%A8%A1%E5%9E%8B/#信号驱动iosignal-driven-io-sigio"},{"categories":["其他"],"content":"\r管道(内核管理的一个缓冲区) 匿名管道：通常用于父子进程的通信(通过fork复制父进程的信息，关闭父进程的读（或写）通道和子进程的写（或读）通道从而形成单向通信的通道) 有名管道：通常用于无亲缘关系进程间的通信 四种读写情况 读端不读（fd[0]未关闭），写端一直写 ：直到管道写满数据后，再次write会导致阻塞，直到管道有空位置才写去数据并返回 写端不写（fd[1]未关闭），但是读端一直读（写端不关闭）：管道为空时阻塞读端，直到管道有数据时才读数据并返回（是否阻塞取决于写端计数器是否大于0….） 读端一直读，且fd[0]保持打开，而写端写了一部分数据不写了，并且关闭fd[1]：读取管道所有数据后返回0 读端读了一部分数据，不读了且关闭fd[0]，写端一直在写且f[1]还保持打开状态：一旦读端关闭而进程write时会接受信号SIGPIPE，通常导致进程异常终止 局限性 只支持单向数据流 缓冲区有限，管道只存在于主存中 所传送的是无格式字节流 效率低下（写数据需要读端读取后才返回） 需要注意同步问题？(自带有同步机制) 有名管道：长期存于系统中，使用不当容易出错 ","date":"2020-07-03","objectID":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/:0:0","series":null,"tags":null,"title":"进程间通讯","uri":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/#管道内核管理的一个缓冲区"},{"categories":["其他"],"content":"\r消息队列 实际上就是信息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信息的传递经过四次信息复制：写端-\u003e内核 内核-\u003e读端(消息队列中信息的复制需要额外消耗CPU的时间．不适宜于信息量大或操作频繁的场合) 消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特点 可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便 ","date":"2020-07-03","objectID":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/:0:0","series":null,"tags":null,"title":"进程间通讯","uri":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/#消息队列"},{"categories":["其他"],"content":"\r共享内存 内存共享机制：将进程的虚拟地址空间映射到相同的物理内存中 该做法会引起进程的内存竞争问题 共享内存是最快的IPC(进程间通信)方式 ","date":"2020-07-03","objectID":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/:0:0","series":null,"tags":null,"title":"进程间通讯","uri":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/#共享内存"},{"categories":["其他"],"content":"\r信号量 用于实现进程间的互斥同步问题 ","date":"2020-07-03","objectID":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/:0:0","series":null,"tags":null,"title":"进程间通讯","uri":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/#信号量"},{"categories":["其他"],"content":"\rsocket 不同主机间进程通信的主要方法 ","date":"2020-07-03","objectID":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/:0:0","series":null,"tags":null,"title":"进程间通讯","uri":"/posts/other/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E8%AE%AF/#socket"}]